{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EfL63wdcdKUfaxdXdYGAT7U1UjcB69sf",
      "authorship_tag": "ABX9TyPu3b6mwkXiFPf/r62yyGAC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd5sOYEDpG82"
      },
      "outputs": [],
      "source": [
        "import numpy as np #Linear algebra and mathematical operations\n",
        "import pandas as pd #importing and loading data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df = pd.read_csv(\"/content/drive/MyDrive/Data Science /Iris.csv\")\n",
        "iris_df = iris_df.sample(frac=1).reset_index(drop=True) # Shuffle"
      ],
      "metadata": {
        "id": "qLm4IFNGpI1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iSr--LJppKen",
        "outputId": "023a128c-706a-4cd6-eef8-631c671316cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
              "0   82            5.5           2.4            3.7           1.0   \n",
              "1   86            6.0           3.4            4.5           1.6   \n",
              "2   80            5.7           2.6            3.5           1.0   \n",
              "3   45            5.1           3.8            1.9           0.4   \n",
              "4  122            5.6           2.8            4.9           2.0   \n",
              "\n",
              "           Species  \n",
              "0  Iris-versicolor  \n",
              "1  Iris-versicolor  \n",
              "2  Iris-versicolor  \n",
              "3      Iris-setosa  \n",
              "4   Iris-virginica  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-544de99e-a680-476d-b59d-d731262631c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82</td>\n",
              "      <td>5.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>122</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-544de99e-a680-476d-b59d-d731262631c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-544de99e-a680-476d-b59d-d731262631c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-544de99e-a680-476d-b59d-d731262631c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = iris_df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "X = np.array(X)\n",
        "X[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-WpbyrqpL3E",
        "outputId": "255814e4-8848-4156-a530-591c268f945b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.5, 2.4, 3.7, 1. ],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [5.6, 2.8, 4.9, 2. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "Y = iris_df.Species\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
        "Y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkjVhIqBpNzf",
        "outputId": "7dc376ed-25be-4f6e-c8ea-9542409f1294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)"
      ],
      "metadata": {
        "id": "RZRvzGfApQm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN_Classification():\n",
        "\n",
        "  \n",
        "    def __init__ (self, hidden_Layer_Size = [100,], learning_Rate = 0.001, epochs = 10,  hyperparameter = False):\n",
        "        self.hidden_Layer_Size = hidden_Layer_Size\n",
        "        self.learning_Rate = learning_Rate\n",
        "        self.epochs = epochs\n",
        "       # self.activation_function = activation_function\n",
        "        self.weights = None\n",
        "        self.hyperparameter = hyperparameter\n",
        "\n",
        "    \n",
        "    def sigmoid(self, x, derivative=False):\n",
        "        if derivative:\n",
        "            return np.multiply(x, 1-x)\n",
        "        return 1/(1 + np.exp(-x))\n",
        "        \n",
        "\n",
        "    def softmax(self, x):\n",
        "        # Numerically stable with large exponentials\n",
        "        exps = np.exp(x - x.max())\n",
        "        return exps / np.sum(exps, axis=0)\n",
        "            \n",
        "\n",
        "    #function for forward propogation\n",
        "    def forward_Prop(self, x, layers):\n",
        "        activations, layer_input = [x], x\n",
        "        for j in range(layers):\n",
        "         # i = \n",
        "          #print(\"i = \"+str(i))\n",
        "          if j <= (layers-1):\n",
        "\n",
        "            activation = self.sigmoid(np.dot(layer_input, self.weights[j].T))\n",
        "            activations.append(activation)\n",
        "            layer_input = np.append(1, activation)\n",
        "\n",
        "          else :\n",
        "            activation = self.softmax(np.dot(layer_input, self.weights[j].T))\n",
        "            activations.append(activation)\n",
        "            layer_input = np.append(1, activation)\n",
        "\n",
        "        return activations\n",
        "\n",
        "\n",
        "    def back_prop(self, y, activations, layers):\n",
        "      outputFinal = activations[-1]\n",
        "      error = np.matrix(y - outputFinal) \n",
        "      \n",
        "      # Error after 1 cycle\n",
        "      for j in range(layers, 0, -1):\n",
        "        currActivation = activations[j]\n",
        "       \n",
        "        if(j > 1):\n",
        "          # Append previous\n",
        "          prevActivation = np.append(1, activations[j-1])\n",
        "        else:\n",
        "          # First hidden layer\n",
        "          prevActivation = activations[0]\n",
        "       \n",
        "        delta = np.multiply(error, self.sigmoid(currActivation, derivative = True))\n",
        "        self.weights[j-1] += self.learning_Rate * np.multiply(delta.T, prevActivation)\n",
        "         \n",
        "        wc = np.delete(self.weights[j-1], [0], axis=1)\n",
        "        error = np.dot(delta, wc) #current layer error\n",
        "       \n",
        "      return self.weights\n",
        "\n",
        "    \n",
        "    def initialize_Weight(self, layers):\n",
        "      layer, self.weights = len(layers), []\n",
        "      #for loop to intialize the weight randomly\n",
        "      for i in range(1, layer):\n",
        "        #assigning random weights\n",
        "        w = [[np.random.uniform(-1, 1) for j in range(layers[i-1] + 1)]for k in range(layers[i])]\n",
        "        self.weights.append(np.matrix(w))\n",
        "    \n",
        "      return self.weights\n",
        "    \n",
        "\n",
        "    #train function\n",
        "    def train(self, X, y):\n",
        "        layers_weights = len(self.weights)\n",
        "        \n",
        "        for i in range(len(self.X)):\n",
        "          x, y = self.X[i], self.y[i]\n",
        "          x = np.matrix(np.append(1, x))\n",
        "          \n",
        "          activations = self.forward_Prop(x, layers_weights)\n",
        "          self.weights = self.back_prop(y, activations, layers_weights)\n",
        "          \n",
        "        return self.weights\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        intiate_time = time.perf_counter()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        hidden_Layers = len(self.hidden_Layer_Size) - 1\n",
        "        self.weights = self.initialize_Weight(self.hidden_Layer_Size)\n",
        "\n",
        "        for epoch in range(1, self.epochs+1):\n",
        "          epoch_intiate_time = time.perf_counter()\n",
        "          weights = self.train(self.X, self.y)\n",
        "\n",
        "          epoch_closing_time = time.perf_counter()\n",
        "          closing_time = time.perf_counter()\n",
        "          \n",
        "          epoch_total_time = epoch_closing_time - epoch_intiate_time\n",
        "          total_time = closing_time - intiate_time\n",
        "          \n",
        "          if self.hyperparameter == False:\n",
        "            print (\"Epoch : {}\".format(epoch))\n",
        "            print (\"Elapsed Time : {}\".format(total_time))\n",
        "            print (\"Step Time : {}\\n\\n\".format(epoch_total_time))\n",
        "            \n",
        "        return self.weights\n",
        "\n",
        "        \n",
        "    def Predict(self, X):\n",
        "        result = []\n",
        "        for i in range(len(X)):\n",
        "          x = X[i]\n",
        "          #print(str(i) + \" \" + str(len(X)))\n",
        "          layers = len(self.weights)\n",
        "          item = np.append(1, x)\n",
        "\n",
        "          # Forward prop.\n",
        "          activations = self.forward_Prop(item, layers)\n",
        "          \n",
        "          Final_output = activations[-1].A1\n",
        "          index = self.FindMaxActivation(Final_output)\n",
        "          \n",
        "          predicted = [0 for j in range(len(Final_output))]\n",
        "          predicted[index] = 1 \n",
        "      \n",
        "          \n",
        "          result.append(predicted)\n",
        "        \n",
        "        return result\n",
        "      \n",
        "    def FindMaxActivation(self, output):\n",
        "        m, index = output[0], 0\n",
        "        for i in range(1, len(output)):\n",
        "          if(output[i] > m):\n",
        "            m, index = output[i], i\n",
        "        \n",
        "        return index"
      ],
      "metadata": {
        "id": "6RagIWqjpO0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = len(X[0]) # no. of features\n",
        "output = len(Y[0]) # no. of classes\n",
        "\n",
        "# Define hyperparameters to search over\n",
        "hidden_layer_sizes = [[first, 50, output], [first, 100, output], [first, 50, 50, output], [first, 100, 100, output]]\n",
        "learning_rates = [0.001, 0.01, 0.1, 0.15, 0.05]\n",
        "epochs = [10, 20, 30, 100, 200]\n",
        "\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "\n",
        "# Loop over all possible hyperparameter combinations\n",
        "for hidden_size in hidden_layer_sizes:\n",
        "    for lr in learning_rates:\n",
        "        for epoch in epochs:\n",
        "            \n",
        "            model = ANN_Classification(hidden_Layer_Size=hidden_size, learning_Rate=lr, epochs=epoch, hyperparameter = True)\n",
        "            model.fit(X_train, Y_train)\n",
        "            \n",
        "            y_pred = model.Predict(X_test)\n",
        "            score = accuracy_score(Y_test, y_pred)\n",
        "            \n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = {'hidden_Layer_Size': hidden_size, 'learning_Rate': lr, 'epochs': epoch}\n",
        "\n",
        "final_model = ANN_Classification(**best_params)\n",
        "final_model.fit(np.concatenate([X_train, X_test]), np.concatenate([Y_train, Y_test]))\n",
        "\n",
        "\n",
        "y_pred_aht = final_model.Predict(X_test)\n",
        "final_score = accuracy_score(Y_test, y_pred_aht)\n",
        "print(\"Best Parameters : {}\".format(best_params))\n",
        "print(\"Final Score = {}\".format(final_score))"
      ],
      "metadata": {
        "id": "Y_ag5epWX6ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4bfa4d-030f-45df-8290-dbd92fc27bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "Elapsed Time : 0.04345069600003626\n",
            "Step Time : 0.041986236000411736\n",
            "\n",
            "\n",
            "Epoch : 2\n",
            "Elapsed Time : 0.08470971200040367\n",
            "Step Time : 0.03991207600029156\n",
            "\n",
            "\n",
            "Epoch : 3\n",
            "Elapsed Time : 0.12224845800028561\n",
            "Step Time : 0.03645719599990116\n",
            "\n",
            "\n",
            "Epoch : 4\n",
            "Elapsed Time : 0.15226905600047758\n",
            "Step Time : 0.029168797999773233\n",
            "\n",
            "\n",
            "Epoch : 5\n",
            "Elapsed Time : 0.18499893199987127\n",
            "Step Time : 0.03190725700005714\n",
            "\n",
            "\n",
            "Epoch : 6\n",
            "Elapsed Time : 0.21441254999990633\n",
            "Step Time : 0.028565716999764845\n",
            "\n",
            "\n",
            "Epoch : 7\n",
            "Elapsed Time : 0.24528505699981906\n",
            "Step Time : 0.03005738800038671\n",
            "\n",
            "\n",
            "Epoch : 8\n",
            "Elapsed Time : 0.2824066330003916\n",
            "Step Time : 0.03615322599944193\n",
            "\n",
            "\n",
            "Epoch : 9\n",
            "Elapsed Time : 0.31678266000017175\n",
            "Step Time : 0.03417305699986173\n",
            "\n",
            "\n",
            "Epoch : 10\n",
            "Elapsed Time : 0.34606215700023313\n",
            "Step Time : 0.029075157000079344\n",
            "\n",
            "\n",
            "Epoch : 11\n",
            "Elapsed Time : 0.37579741399986233\n",
            "Step Time : 0.02855480800008081\n",
            "\n",
            "\n",
            "Epoch : 12\n",
            "Elapsed Time : 0.4096572010003001\n",
            "Step Time : 0.033654326999567274\n",
            "\n",
            "\n",
            "Epoch : 13\n",
            "Elapsed Time : 0.44071867799993925\n",
            "Step Time : 0.03085348700005852\n",
            "\n",
            "\n",
            "Epoch : 14\n",
            "Elapsed Time : 0.4890740239998195\n",
            "Step Time : 0.04740600600052858\n",
            "\n",
            "\n",
            "Epoch : 15\n",
            "Elapsed Time : 0.5241624899999806\n",
            "Step Time : 0.03438339599961182\n",
            "\n",
            "\n",
            "Epoch : 16\n",
            "Elapsed Time : 0.5570005770005082\n",
            "Step Time : 0.0322389769999063\n",
            "\n",
            "\n",
            "Epoch : 17\n",
            "Elapsed Time : 0.5977192039999863\n",
            "Step Time : 0.04051744600019447\n",
            "\n",
            "\n",
            "Epoch : 18\n",
            "Elapsed Time : 0.642174069000248\n",
            "Step Time : 0.0434814260006533\n",
            "\n",
            "\n",
            "Epoch : 19\n",
            "Elapsed Time : 0.671801645999949\n",
            "Step Time : 0.02835688699997263\n",
            "\n",
            "\n",
            "Epoch : 20\n",
            "Elapsed Time : 0.7024087340005281\n",
            "Step Time : 0.030397948000427277\n",
            "\n",
            "\n",
            "Best Parameters : {'hidden_Layer_Size': [4, 50, 3], 'learning_Rate': 0.01, 'epochs': 20}\n",
            "Final Score = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first = len(X[0]) # no. of features\n",
        "output = len(Y[0]) # no. of classes\n",
        "\n",
        "layers = [first, 5, 10, output] # no. of nodes \n",
        "L, E = 0.15, 200\n",
        "#calling neural network function\n",
        "weights = ANN_Classification(hidden_Layer_Size = layers, epochs=E, learning_Rate = L)"
      ],
      "metadata": {
        "id": "aStWnuliR1tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = weights.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "J9xxbxOZ0ueh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79d4614-8fe0-411a-ead0-ef1c742a487b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "Elapsed Time : 0.06136934400001337\n",
            "Step Time : 0.06061829400005081\n",
            "\n",
            "\n",
            "Epoch : 2\n",
            "Elapsed Time : 0.11987904800025717\n",
            "Step Time : 0.05710176400043565\n",
            "\n",
            "\n",
            "Epoch : 3\n",
            "Elapsed Time : 0.1765031530003398\n",
            "Step Time : 0.055488805000095454\n",
            "\n",
            "\n",
            "Epoch : 4\n",
            "Elapsed Time : 0.22845579800014093\n",
            "Step Time : 0.05082275499989919\n",
            "\n",
            "\n",
            "Epoch : 5\n",
            "Elapsed Time : 0.2797742329994435\n",
            "Step Time : 0.05018643499988684\n",
            "\n",
            "\n",
            "Epoch : 6\n",
            "Elapsed Time : 0.32910916800028645\n",
            "Step Time : 0.048094865000166465\n",
            "\n",
            "\n",
            "Epoch : 7\n",
            "Elapsed Time : 0.38141330300004483\n",
            "Step Time : 0.05119512599958398\n",
            "\n",
            "\n",
            "Epoch : 8\n",
            "Elapsed Time : 0.43381238900019525\n",
            "Step Time : 0.05130955599997833\n",
            "\n",
            "\n",
            "Epoch : 9\n",
            "Elapsed Time : 0.4854090039998482\n",
            "Step Time : 0.050402185000166355\n",
            "\n",
            "\n",
            "Epoch : 10\n",
            "Elapsed Time : 0.5339897989997553\n",
            "Step Time : 0.04743967500053259\n",
            "\n",
            "\n",
            "Epoch : 11\n",
            "Elapsed Time : 0.5940276629999062\n",
            "Step Time : 0.05888806500024657\n",
            "\n",
            "\n",
            "Epoch : 12\n",
            "Elapsed Time : 0.6456019090001064\n",
            "Step Time : 0.05041591499957576\n",
            "\n",
            "\n",
            "Epoch : 13\n",
            "Elapsed Time : 0.7012694630002443\n",
            "Step Time : 0.05543918500006839\n",
            "\n",
            "\n",
            "Epoch : 14\n",
            "Elapsed Time : 0.7534433379996699\n",
            "Step Time : 0.050791634999768576\n",
            "\n",
            "\n",
            "Epoch : 15\n",
            "Elapsed Time : 0.8018007439995927\n",
            "Step Time : 0.047277685000153724\n",
            "\n",
            "\n",
            "Epoch : 16\n",
            "Elapsed Time : 0.8533275489999141\n",
            "Step Time : 0.05036162499982311\n",
            "\n",
            "\n",
            "Epoch : 17\n",
            "Elapsed Time : 0.9013046339996436\n",
            "Step Time : 0.04774436499974399\n",
            "\n",
            "\n",
            "Epoch : 18\n",
            "Elapsed Time : 0.9641226379999353\n",
            "Step Time : 0.060509603999889805\n",
            "\n",
            "\n",
            "Epoch : 19\n",
            "Elapsed Time : 1.0175269230003323\n",
            "Step Time : 0.0522521949997099\n",
            "\n",
            "\n",
            "Epoch : 20\n",
            "Elapsed Time : 1.0871217470003103\n",
            "Step Time : 0.0693539639996743\n",
            "\n",
            "\n",
            "Epoch : 21\n",
            "Elapsed Time : 1.1498879809996652\n",
            "Step Time : 0.06137778399988747\n",
            "\n",
            "\n",
            "Epoch : 22\n",
            "Elapsed Time : 1.2096030350003275\n",
            "Step Time : 0.058449494000342384\n",
            "\n",
            "\n",
            "Epoch : 23\n",
            "Elapsed Time : 1.2643227199996545\n",
            "Step Time : 0.05362178500035952\n",
            "\n",
            "\n",
            "Epoch : 24\n",
            "Elapsed Time : 1.3132294249999177\n",
            "Step Time : 0.047689474999970116\n",
            "\n",
            "\n",
            "Epoch : 25\n",
            "Elapsed Time : 1.3780371590000868\n",
            "Step Time : 0.06371589399986988\n",
            "\n",
            "\n",
            "Epoch : 26\n",
            "Elapsed Time : 1.432791573999566\n",
            "Step Time : 0.05150390500057256\n",
            "\n",
            "\n",
            "Epoch : 27\n",
            "Elapsed Time : 1.4824715389995617\n",
            "Step Time : 0.04856941500020184\n",
            "\n",
            "\n",
            "Epoch : 28\n",
            "Elapsed Time : 1.5366111940002156\n",
            "Step Time : 0.05389895499956765\n",
            "\n",
            "\n",
            "Epoch : 29\n",
            "Elapsed Time : 1.5893439589999616\n",
            "Step Time : 0.051644424999722105\n",
            "\n",
            "\n",
            "Epoch : 30\n",
            "Elapsed Time : 1.6433815539994612\n",
            "Step Time : 0.05216778499925567\n",
            "\n",
            "\n",
            "Epoch : 31\n",
            "Elapsed Time : 1.6974836190001952\n",
            "Step Time : 0.053010054999504064\n",
            "\n",
            "\n",
            "Epoch : 32\n",
            "Elapsed Time : 1.7525648640003055\n",
            "Step Time : 0.053912155000034545\n",
            "\n",
            "\n",
            "Epoch : 33\n",
            "Elapsed Time : 1.8169287769997027\n",
            "Step Time : 0.06328059299994493\n",
            "\n",
            "\n",
            "Epoch : 34\n",
            "Elapsed Time : 1.870277461999649\n",
            "Step Time : 0.051984804999847256\n",
            "\n",
            "\n",
            "Epoch : 35\n",
            "Elapsed Time : 1.9184401679995062\n",
            "Step Time : 0.04798807599945576\n",
            "\n",
            "\n",
            "Epoch : 36\n",
            "Elapsed Time : 1.9676851730000635\n",
            "Step Time : 0.04816605499945581\n",
            "\n",
            "\n",
            "Epoch : 37\n",
            "Elapsed Time : 2.0338053269997545\n",
            "Step Time : 0.0658938839997063\n",
            "\n",
            "\n",
            "Epoch : 38\n",
            "Elapsed Time : 2.081843201999618\n",
            "Step Time : 0.04683165500046016\n",
            "\n",
            "\n",
            "Epoch : 39\n",
            "Elapsed Time : 2.133012127999791\n",
            "Step Time : 0.05008489500050928\n",
            "\n",
            "\n",
            "Epoch : 40\n",
            "Elapsed Time : 2.181128362999516\n",
            "Step Time : 0.04697781600043527\n",
            "\n",
            "\n",
            "Epoch : 41\n",
            "Elapsed Time : 2.2311308079997616\n",
            "Step Time : 0.048913125000581203\n",
            "\n",
            "\n",
            "Epoch : 42\n",
            "Elapsed Time : 2.2823782529994787\n",
            "Step Time : 0.050161375000243424\n",
            "\n",
            "\n",
            "Epoch : 43\n",
            "Elapsed Time : 2.335995577999711\n",
            "Step Time : 0.05228611499933322\n",
            "\n",
            "\n",
            "Epoch : 44\n",
            "Elapsed Time : 2.3924120530000437\n",
            "Step Time : 0.05534708499999397\n",
            "\n",
            "\n",
            "Epoch : 45\n",
            "Elapsed Time : 2.451751726999646\n",
            "Step Time : 0.058027424000101746\n",
            "\n",
            "\n",
            "Epoch : 46\n",
            "Elapsed Time : 2.5075873019995925\n",
            "Step Time : 0.054704504999790515\n",
            "\n",
            "\n",
            "Epoch : 47\n",
            "Elapsed Time : 2.561270457000319\n",
            "Step Time : 0.05225545499979489\n",
            "\n",
            "\n",
            "Epoch : 48\n",
            "Elapsed Time : 2.620064880999962\n",
            "Step Time : 0.05737617400063755\n",
            "\n",
            "\n",
            "Epoch : 49\n",
            "Elapsed Time : 2.673518175999561\n",
            "Step Time : 0.05207906499981618\n",
            "\n",
            "\n",
            "Epoch : 50\n",
            "Elapsed Time : 2.7274929109998993\n",
            "Step Time : 0.052667824999844015\n",
            "\n",
            "\n",
            "Epoch : 51\n",
            "Elapsed Time : 2.7869492459994945\n",
            "Step Time : 0.05817729399950622\n",
            "\n",
            "\n",
            "Epoch : 52\n",
            "Elapsed Time : 2.830124080999667\n",
            "Step Time : 0.04264257600061683\n",
            "\n",
            "\n",
            "Epoch : 53\n",
            "Elapsed Time : 2.866266588000144\n",
            "Step Time : 0.03528234700024768\n",
            "\n",
            "\n",
            "Epoch : 54\n",
            "Elapsed Time : 2.9098215940002774\n",
            "Step Time : 0.0426907660003053\n",
            "\n",
            "\n",
            "Epoch : 55\n",
            "Elapsed Time : 2.952649830000155\n",
            "Step Time : 0.04176128699964465\n",
            "\n",
            "\n",
            "Epoch : 56\n",
            "Elapsed Time : 2.9867105260000244\n",
            "Step Time : 0.0332665559999441\n",
            "\n",
            "\n",
            "Epoch : 57\n",
            "Elapsed Time : 3.044527520999509\n",
            "Step Time : 0.056745054999737476\n",
            "\n",
            "\n",
            "Epoch : 58\n",
            "Elapsed Time : 3.08370617699984\n",
            "Step Time : 0.03844552600003226\n",
            "\n",
            "\n",
            "Epoch : 59\n",
            "Elapsed Time : 3.1167185739996057\n",
            "Step Time : 0.031730216999676486\n",
            "\n",
            "\n",
            "Epoch : 60\n",
            "Elapsed Time : 3.1527965610002866\n",
            "Step Time : 0.035856536999745\n",
            "\n",
            "\n",
            "Epoch : 61\n",
            "Elapsed Time : 3.193966736999755\n",
            "Step Time : 0.03928273600013199\n",
            "\n",
            "\n",
            "Epoch : 62\n",
            "Elapsed Time : 3.2657892999995966\n",
            "Step Time : 0.07057777299996815\n",
            "\n",
            "\n",
            "Epoch : 63\n",
            "Elapsed Time : 3.299909317000129\n",
            "Step Time : 0.03391120700052852\n",
            "\n",
            "\n",
            "Epoch : 64\n",
            "Elapsed Time : 3.335460033000345\n",
            "Step Time : 0.035369567000088864\n",
            "\n",
            "\n",
            "Epoch : 65\n",
            "Elapsed Time : 3.3856120479995298\n",
            "Step Time : 0.049961714999881224\n",
            "\n",
            "\n",
            "Epoch : 66\n",
            "Elapsed Time : 3.427481435000118\n",
            "Step Time : 0.0416384760001165\n",
            "\n",
            "\n",
            "Epoch : 67\n",
            "Elapsed Time : 3.463091620999876\n",
            "Step Time : 0.035395425999922736\n",
            "\n",
            "\n",
            "Epoch : 68\n",
            "Elapsed Time : 3.507969096999659\n",
            "Step Time : 0.04370007600027748\n",
            "\n",
            "\n",
            "Epoch : 69\n",
            "Elapsed Time : 3.545217412999591\n",
            "Step Time : 0.03656160699938482\n",
            "\n",
            "\n",
            "Epoch : 70\n",
            "Elapsed Time : 3.577883330000077\n",
            "Step Time : 0.032466826000018045\n",
            "\n",
            "\n",
            "Epoch : 71\n",
            "Elapsed Time : 3.631925075000254\n",
            "Step Time : 0.05289674499999819\n",
            "\n",
            "\n",
            "Epoch : 72\n",
            "Elapsed Time : 3.6663988419995803\n",
            "Step Time : 0.03299302699997497\n",
            "\n",
            "\n",
            "Epoch : 73\n",
            "Elapsed Time : 3.7013562889997047\n",
            "Step Time : 0.03475890699974116\n",
            "\n",
            "\n",
            "Epoch : 74\n",
            "Elapsed Time : 3.751043784000103\n",
            "Step Time : 0.0494853249992957\n",
            "\n",
            "\n",
            "Epoch : 75\n",
            "Elapsed Time : 3.802305309000076\n",
            "Step Time : 0.050998394999624\n",
            "\n",
            "\n",
            "Epoch : 76\n",
            "Elapsed Time : 3.8668091930003357\n",
            "Step Time : 0.06428599399987434\n",
            "\n",
            "\n",
            "Epoch : 77\n",
            "Elapsed Time : 3.9058364689999507\n",
            "Step Time : 0.03881941600047867\n",
            "\n",
            "\n",
            "Epoch : 78\n",
            "Elapsed Time : 3.9450732759996754\n",
            "Step Time : 0.038253396000072826\n",
            "\n",
            "\n",
            "Epoch : 79\n",
            "Elapsed Time : 3.9788499520000187\n",
            "Step Time : 0.0324944569993022\n",
            "\n",
            "\n",
            "Epoch : 80\n",
            "Elapsed Time : 4.0202695489997495\n",
            "Step Time : 0.04122392699991906\n",
            "\n",
            "\n",
            "Epoch : 81\n",
            "Elapsed Time : 4.064010154000243\n",
            "Step Time : 0.04248555599951942\n",
            "\n",
            "\n",
            "Epoch : 82\n",
            "Elapsed Time : 4.114096588999928\n",
            "Step Time : 0.04895327500071289\n",
            "\n",
            "\n",
            "Epoch : 83\n",
            "Elapsed Time : 4.153327375999652\n",
            "Step Time : 0.039013255999634566\n",
            "\n",
            "\n",
            "Epoch : 84\n",
            "Elapsed Time : 4.204142601000058\n",
            "Step Time : 0.050588895000146294\n",
            "\n",
            "\n",
            "Epoch : 85\n",
            "Elapsed Time : 4.2375044379996325\n",
            "Step Time : 0.03314093700009835\n",
            "\n",
            "\n",
            "Epoch : 86\n",
            "Elapsed Time : 4.273441373999958\n",
            "Step Time : 0.0350413269998171\n",
            "\n",
            "\n",
            "Epoch : 87\n",
            "Elapsed Time : 4.30829698100024\n",
            "Step Time : 0.03382365699962975\n",
            "\n",
            "\n",
            "Epoch : 88\n",
            "Elapsed Time : 4.370588134999707\n",
            "Step Time : 0.06209351399957086\n",
            "\n",
            "\n",
            "Epoch : 89\n",
            "Elapsed Time : 4.411564610999449\n",
            "Step Time : 0.040747226000348746\n",
            "\n",
            "\n",
            "Epoch : 90\n",
            "Elapsed Time : 4.452465997000218\n",
            "Step Time : 0.04003488599937555\n",
            "\n",
            "\n",
            "Epoch : 91\n",
            "Elapsed Time : 4.492880124000294\n",
            "Step Time : 0.03686336600003415\n",
            "\n",
            "\n",
            "Epoch : 92\n",
            "Elapsed Time : 4.539134368999839\n",
            "Step Time : 0.045030656000562885\n",
            "\n",
            "\n",
            "Epoch : 93\n",
            "Elapsed Time : 4.576901645999897\n",
            "Step Time : 0.03644135700051265\n",
            "\n",
            "\n",
            "Epoch : 94\n",
            "Elapsed Time : 4.637016259999655\n",
            "Step Time : 0.05951461400036351\n",
            "\n",
            "\n",
            "Epoch : 95\n",
            "Elapsed Time : 4.685701315000188\n",
            "Step Time : 0.04843505600001663\n",
            "\n",
            "\n",
            "Epoch : 96\n",
            "Elapsed Time : 4.718637222000325\n",
            "Step Time : 0.032737665999775345\n",
            "\n",
            "\n",
            "Epoch : 97\n",
            "Elapsed Time : 4.753685849000249\n",
            "Step Time : 0.033834517000286723\n",
            "\n",
            "\n",
            "Epoch : 98\n",
            "Elapsed Time : 4.7892548359996\n",
            "Step Time : 0.03533221700035938\n",
            "\n",
            "\n",
            "Epoch : 99\n",
            "Elapsed Time : 4.826096992000203\n",
            "Step Time : 0.03569047699966177\n",
            "\n",
            "\n",
            "Epoch : 100\n",
            "Elapsed Time : 4.864165128999957\n",
            "Step Time : 0.037112705999788886\n",
            "\n",
            "\n",
            "Epoch : 101\n",
            "Elapsed Time : 4.901350854999691\n",
            "Step Time : 0.035280796999359154\n",
            "\n",
            "\n",
            "Epoch : 102\n",
            "Elapsed Time : 4.956451029999698\n",
            "Step Time : 0.0542684449992521\n",
            "\n",
            "\n",
            "Epoch : 103\n",
            "Elapsed Time : 4.996000475999608\n",
            "Step Time : 0.0393266359997142\n",
            "\n",
            "\n",
            "Epoch : 104\n",
            "Elapsed Time : 5.04900145099964\n",
            "Step Time : 0.05279996499939443\n",
            "\n",
            "\n",
            "Epoch : 105\n",
            "Elapsed Time : 5.1009438860000955\n",
            "Step Time : 0.051732155000536295\n",
            "\n",
            "\n",
            "Epoch : 106\n",
            "Elapsed Time : 5.136312601999634\n",
            "Step Time : 0.034845705999941856\n",
            "\n",
            "\n",
            "Epoch : 107\n",
            "Elapsed Time : 5.17459049900026\n",
            "Step Time : 0.03745539600004122\n",
            "\n",
            "\n",
            "Epoch : 108\n",
            "Elapsed Time : 5.211157855000238\n",
            "Step Time : 0.0358215559999735\n",
            "\n",
            "\n",
            "Epoch : 109\n",
            "Elapsed Time : 5.247149871999682\n",
            "Step Time : 0.035793066999758594\n",
            "\n",
            "\n",
            "Epoch : 110\n",
            "Elapsed Time : 5.283589918999496\n",
            "Step Time : 0.03547081699980481\n",
            "\n",
            "\n",
            "Epoch : 111\n",
            "Elapsed Time : 5.327007115000015\n",
            "Step Time : 0.04323193599975639\n",
            "\n",
            "\n",
            "Epoch : 112\n",
            "Elapsed Time : 5.386619898999925\n",
            "Step Time : 0.05821380500037776\n",
            "\n",
            "\n",
            "Epoch : 113\n",
            "Elapsed Time : 5.425908385000184\n",
            "Step Time : 0.0384091059995626\n",
            "\n",
            "\n",
            "Epoch : 114\n",
            "Elapsed Time : 5.461333162000301\n",
            "Step Time : 0.034539046999270795\n",
            "\n",
            "\n",
            "Epoch : 115\n",
            "Elapsed Time : 5.497558817999561\n",
            "Step Time : 0.03600782600005914\n",
            "\n",
            "\n",
            "Epoch : 116\n",
            "Elapsed Time : 5.532936824999524\n",
            "Step Time : 0.034388777000458504\n",
            "\n",
            "\n",
            "Epoch : 117\n",
            "Elapsed Time : 5.577676001000327\n",
            "Step Time : 0.04453326600014407\n",
            "\n",
            "\n",
            "Epoch : 118\n",
            "Elapsed Time : 5.632813874999556\n",
            "Step Time : 0.054911673999413324\n",
            "\n",
            "\n",
            "Epoch : 119\n",
            "Elapsed Time : 5.673203471999841\n",
            "Step Time : 0.039538185999845155\n",
            "\n",
            "\n",
            "Epoch : 120\n",
            "Elapsed Time : 5.709840888000144\n",
            "Step Time : 0.03638107599999785\n",
            "\n",
            "\n",
            "Epoch : 121\n",
            "Elapsed Time : 5.757130064000194\n",
            "Step Time : 0.047068775999832724\n",
            "\n",
            "\n",
            "Epoch : 122\n",
            "Elapsed Time : 5.7925172599998405\n",
            "Step Time : 0.03522598699964874\n",
            "\n",
            "\n",
            "Epoch : 123\n",
            "Elapsed Time : 5.825085526999828\n",
            "Step Time : 0.03135147700049856\n",
            "\n",
            "\n",
            "Epoch : 124\n",
            "Elapsed Time : 5.8706480729997566\n",
            "Step Time : 0.04482929599998897\n",
            "\n",
            "\n",
            "Epoch : 125\n",
            "Elapsed Time : 5.907668848999492\n",
            "Step Time : 0.03685462700013886\n",
            "\n",
            "\n",
            "Epoch : 126\n",
            "Elapsed Time : 5.941797255999518\n",
            "Step Time : 0.033390716000212706\n",
            "\n",
            "\n",
            "Epoch : 127\n",
            "Elapsed Time : 5.997439980999843\n",
            "Step Time : 0.05437474500013195\n",
            "\n",
            "\n",
            "Epoch : 128\n",
            "Elapsed Time : 6.034455496999726\n",
            "Step Time : 0.03680404700025974\n",
            "\n",
            "\n",
            "Epoch : 129\n",
            "Elapsed Time : 6.069070423999619\n",
            "Step Time : 0.03441332700003841\n",
            "\n",
            "\n",
            "Epoch : 130\n",
            "Elapsed Time : 6.121046538999508\n",
            "Step Time : 0.051401575000454613\n",
            "\n",
            "\n",
            "Epoch : 131\n",
            "Elapsed Time : 6.162831744999494\n",
            "Step Time : 0.04153182600020955\n",
            "\n",
            "\n",
            "Epoch : 132\n",
            "Elapsed Time : 6.19788501199946\n",
            "Step Time : 0.034834037000109674\n",
            "\n",
            "\n",
            "Epoch : 133\n",
            "Elapsed Time : 6.242607907000092\n",
            "Step Time : 0.044528125999931945\n",
            "\n",
            "\n",
            "Epoch : 134\n",
            "Elapsed Time : 6.297037761999491\n",
            "Step Time : 0.054214034999858995\n",
            "\n",
            "\n",
            "Epoch : 135\n",
            "Elapsed Time : 6.347345608000069\n",
            "Step Time : 0.049335685999722045\n",
            "\n",
            "\n",
            "Epoch : 136\n",
            "Elapsed Time : 6.383826174000205\n",
            "Step Time : 0.03627298600076756\n",
            "\n",
            "\n",
            "Epoch : 137\n",
            "Elapsed Time : 6.429870629999641\n",
            "Step Time : 0.045838086000003386\n",
            "\n",
            "\n",
            "Epoch : 138\n",
            "Elapsed Time : 6.48803312400014\n",
            "Step Time : 0.05794723399958457\n",
            "\n",
            "\n",
            "Epoch : 139\n",
            "Elapsed Time : 6.5232236609999745\n",
            "Step Time : 0.03399914700003137\n",
            "\n",
            "\n",
            "Epoch : 140\n",
            "Elapsed Time : 6.559367308000219\n",
            "Step Time : 0.03521549600009166\n",
            "\n",
            "\n",
            "Epoch : 141\n",
            "Elapsed Time : 6.596116814000197\n",
            "Step Time : 0.035867927000253985\n",
            "\n",
            "\n",
            "Epoch : 142\n",
            "Elapsed Time : 6.659670207999625\n",
            "Step Time : 0.06332979400031036\n",
            "\n",
            "\n",
            "Epoch : 143\n",
            "Elapsed Time : 6.715553942999577\n",
            "Step Time : 0.0549262650001765\n",
            "\n",
            "\n",
            "Epoch : 144\n",
            "Elapsed Time : 6.770274438000342\n",
            "Step Time : 0.054535084999770334\n",
            "\n",
            "\n",
            "Epoch : 145\n",
            "Elapsed Time : 6.813955044000068\n",
            "Step Time : 0.04334733499945287\n",
            "\n",
            "\n",
            "Epoch : 146\n",
            "Elapsed Time : 6.855883909000113\n",
            "Step Time : 0.04102751600021293\n",
            "\n",
            "\n",
            "Epoch : 147\n",
            "Elapsed Time : 6.8973620360002315\n",
            "Step Time : 0.04127749600047537\n",
            "\n",
            "\n",
            "Epoch : 148\n",
            "Elapsed Time : 6.95329417099947\n",
            "Step Time : 0.05574075500044273\n",
            "\n",
            "\n",
            "Epoch : 149\n",
            "Elapsed Time : 7.023606304000168\n",
            "Step Time : 0.07007847400018363\n",
            "\n",
            "\n",
            "Epoch : 150\n",
            "Elapsed Time : 7.068221800000174\n",
            "Step Time : 0.043935795999459515\n",
            "\n",
            "\n",
            "Epoch : 151\n",
            "Elapsed Time : 7.1126520649995655\n",
            "Step Time : 0.04320254600042972\n",
            "\n",
            "\n",
            "Epoch : 152\n",
            "Elapsed Time : 7.152554250999856\n",
            "Step Time : 0.039639986000111094\n",
            "\n",
            "\n",
            "Epoch : 153\n",
            "Elapsed Time : 7.236087733999739\n",
            "Step Time : 0.08234502199957205\n",
            "\n",
            "\n",
            "Epoch : 154\n",
            "Elapsed Time : 7.269636899999568\n",
            "Step Time : 0.032679637000001094\n",
            "\n",
            "\n",
            "Epoch : 155\n",
            "Elapsed Time : 7.306269376999808\n",
            "Step Time : 0.03550004699991405\n",
            "\n",
            "\n",
            "Epoch : 156\n",
            "Elapsed Time : 7.343484772999545\n",
            "Step Time : 0.03620765600044251\n",
            "\n",
            "\n",
            "Epoch : 157\n",
            "Elapsed Time : 7.380152109999472\n",
            "Step Time : 0.035549657000046864\n",
            "\n",
            "\n",
            "Epoch : 158\n",
            "Elapsed Time : 7.426641205000124\n",
            "Step Time : 0.04560359500010236\n",
            "\n",
            "\n",
            "Epoch : 159\n",
            "Elapsed Time : 7.469503170999815\n",
            "Step Time : 0.04129047599963087\n",
            "\n",
            "\n",
            "Epoch : 160\n",
            "Elapsed Time : 7.505298948000018\n",
            "Step Time : 0.03558975699979783\n",
            "\n",
            "\n",
            "Epoch : 161\n",
            "Elapsed Time : 7.553752722999889\n",
            "Step Time : 0.04821945500043512\n",
            "\n",
            "\n",
            "Epoch : 162\n",
            "Elapsed Time : 7.5892336500000965\n",
            "Step Time : 0.03530483699978504\n",
            "\n",
            "\n",
            "Epoch : 163\n",
            "Elapsed Time : 7.629730845999802\n",
            "Step Time : 0.039221856000040134\n",
            "\n",
            "\n",
            "Epoch : 164\n",
            "Elapsed Time : 7.679559971999879\n",
            "Step Time : 0.04962526599956618\n",
            "\n",
            "\n",
            "Epoch : 165\n",
            "Elapsed Time : 7.729257357000279\n",
            "Step Time : 0.049044536000110384\n",
            "\n",
            "\n",
            "Epoch : 166\n",
            "Elapsed Time : 7.763601652999569\n",
            "Step Time : 0.03344577699954243\n",
            "\n",
            "\n",
            "Epoch : 167\n",
            "Elapsed Time : 7.806428449000123\n",
            "Step Time : 0.04200845600007597\n",
            "\n",
            "\n",
            "Epoch : 168\n",
            "Elapsed Time : 7.8566821550002715\n",
            "Step Time : 0.04916438599957473\n",
            "\n",
            "\n",
            "Epoch : 169\n",
            "Elapsed Time : 7.927396177999981\n",
            "Step Time : 0.07049167300010595\n",
            "\n",
            "\n",
            "Epoch : 170\n",
            "Elapsed Time : 7.9723013439997885\n",
            "Step Time : 0.04394612599935499\n",
            "\n",
            "\n",
            "Epoch : 171\n",
            "Elapsed Time : 8.007686289999583\n",
            "Step Time : 0.03462736700021196\n",
            "\n",
            "\n",
            "Epoch : 172\n",
            "Elapsed Time : 8.046159317000274\n",
            "Step Time : 0.03762742700018862\n",
            "\n",
            "\n",
            "Epoch : 173\n",
            "Elapsed Time : 8.081610422999802\n",
            "Step Time : 0.03523090599992429\n",
            "\n",
            "\n",
            "Epoch : 174\n",
            "Elapsed Time : 8.121713210000053\n",
            "Step Time : 0.03989548699973966\n",
            "\n",
            "\n",
            "Epoch : 175\n",
            "Elapsed Time : 8.187778503000118\n",
            "Step Time : 0.06585468399953243\n",
            "\n",
            "\n",
            "Epoch : 176\n",
            "Elapsed Time : 8.240039958000125\n",
            "Step Time : 0.05182668500037835\n",
            "\n",
            "\n",
            "Epoch : 177\n",
            "Elapsed Time : 8.277639173999887\n",
            "Step Time : 0.036180265999973926\n",
            "\n",
            "\n",
            "Epoch : 178\n",
            "Elapsed Time : 8.313378310999724\n",
            "Step Time : 0.03554998599975079\n",
            "\n",
            "\n",
            "Epoch : 179\n",
            "Elapsed Time : 8.351345258000038\n",
            "Step Time : 0.037762596999527887\n",
            "\n",
            "\n",
            "Epoch : 180\n",
            "Elapsed Time : 8.391458313999465\n",
            "Step Time : 0.0374928560004264\n",
            "\n",
            "\n",
            "Epoch : 181\n",
            "Elapsed Time : 8.471290866000345\n",
            "Step Time : 0.07896772200001578\n",
            "\n",
            "\n",
            "Epoch : 182\n",
            "Elapsed Time : 8.520714790999591\n",
            "Step Time : 0.049225755000406934\n",
            "\n",
            "\n",
            "Epoch : 183\n",
            "Elapsed Time : 8.556234378000227\n",
            "Step Time : 0.03529895599967858\n",
            "\n",
            "\n",
            "Epoch : 184\n",
            "Elapsed Time : 8.595210734999455\n",
            "Step Time : 0.038775697000346554\n",
            "\n",
            "\n",
            "Epoch : 185\n",
            "Elapsed Time : 8.636215820999496\n",
            "Step Time : 0.04014585699951567\n",
            "\n",
            "\n",
            "Epoch : 186\n",
            "Elapsed Time : 8.6697610479996\n",
            "Step Time : 0.032278005999614834\n",
            "\n",
            "\n",
            "Epoch : 187\n",
            "Elapsed Time : 8.728065192000031\n",
            "Step Time : 0.058081484000467754\n",
            "\n",
            "\n",
            "Epoch : 188\n",
            "Elapsed Time : 8.770343657999547\n",
            "Step Time : 0.04203240600054414\n",
            "\n",
            "\n",
            "Epoch : 189\n",
            "Elapsed Time : 8.805674545000329\n",
            "Step Time : 0.035133837000103085\n",
            "\n",
            "\n",
            "Epoch : 190\n",
            "Elapsed Time : 8.861321219000274\n",
            "Step Time : 0.05461547499999142\n",
            "\n",
            "\n",
            "Epoch : 191\n",
            "Elapsed Time : 8.89605023599961\n",
            "Step Time : 0.033918097000423586\n",
            "\n",
            "\n",
            "Epoch : 192\n",
            "Elapsed Time : 8.932195762999982\n",
            "Step Time : 0.03592247699998552\n",
            "\n",
            "\n",
            "Epoch : 193\n",
            "Elapsed Time : 8.976483778999864\n",
            "Step Time : 0.043156246999387804\n",
            "\n",
            "\n",
            "Epoch : 194\n",
            "Elapsed Time : 9.012910294999529\n",
            "Step Time : 0.036202407000018866\n",
            "\n",
            "\n",
            "Epoch : 195\n",
            "Elapsed Time : 9.046051241999521\n",
            "Step Time : 0.031906756999887875\n",
            "\n",
            "\n",
            "Epoch : 196\n",
            "Elapsed Time : 9.082438868000281\n",
            "Step Time : 0.03615853599967522\n",
            "\n",
            "\n",
            "Epoch : 197\n",
            "Elapsed Time : 9.159718230999715\n",
            "Step Time : 0.07629660299971874\n",
            "\n",
            "\n",
            "Epoch : 198\n",
            "Elapsed Time : 9.206223526999565\n",
            "Step Time : 0.045957455999996455\n",
            "\n",
            "\n",
            "Epoch : 199\n",
            "Elapsed Time : 9.25422785199953\n",
            "Step Time : 0.047039954999490874\n",
            "\n",
            "\n",
            "Epoch : 200\n",
            "Elapsed Time : 9.289244898999641\n",
            "Step Time : 0.034167056000114826\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_manual = weights.Predict(X_test)\n",
        "score_manual = accuracy_score(Y_test, y_pred_manual)"
      ],
      "metadata": {
        "id": "Pfpb2s502raJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Keras**"
      ],
      "metadata": {
        "id": "gYA8lM8eFetj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "fcU7yZaPADDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(5, input_shape=(4,), activation='sigmoid', name='h1'))\n",
        "model.add(Dense(10, activation='sigmoid', name='h2'))\n",
        "model.add(Dense(3, activation='softmax', name='output'))\n",
        "\n",
        "# Adam optimizer with learning rate of 0.001\n",
        "optimizer = Adam(lr=0.15)\n",
        "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Zm_s9XADAz",
        "outputId": "d2b2db83-2016-4d72-c78d-7bf73d3395a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh4Hom5JAC54",
        "outputId": "d16967a3-9e3e-4015-8df5-4f30f09fb719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1655 - accuracy: 0.3937\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.4646\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.6614\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7874\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7559\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8976\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.9213\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9528\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9291\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9291\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2315 - accuracy: 0.9055\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8898\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9449\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9685\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9764\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9685\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9764\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9685\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9449\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9606\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9764\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9685\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9528\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9449\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9370\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9291\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9606\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9685\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9606\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9213\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9606\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9764\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9685\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9921\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9764\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9606\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9606\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9449\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9606\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9764\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9685\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9843\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9606\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9685\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9685\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9606\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9921\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9685\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9528\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9764\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9528\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9449\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9606\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9685\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9685\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9606\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9606\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9764\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9843\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9764\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9528\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9685\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9843\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9606\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9528\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9370\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9685\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9606\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9449\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9528\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9921\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9764\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9843\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9685\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9528\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9370\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 0.9055\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9291\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9370\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9370\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9606\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9685\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9685\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9764\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9528\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9606\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9606\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9606\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9528\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9528\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9685\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9528\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9606\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9606\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9685\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9606\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9685\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9685\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9764\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9843\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9764\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9685\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9764\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9843\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9843\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9843\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9843\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9764\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9764\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9449\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2240 - accuracy: 0.9370\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9449\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9606\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9606\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9764\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9606\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9843\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9764\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9843\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9764\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9685\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9843\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9764\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9921\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9764\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9843\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9528\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9764\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9764\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9764\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9606\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9685\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0838 - accuracy: 0.9606\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9606\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9764\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9606\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9606\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9843\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9764\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9843\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9764\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9764\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9764\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9843\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9843\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9843\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9764\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9764\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9921\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9843\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9685\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9606\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9528\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9606\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9528\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9764\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9528\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9685\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9843\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9764\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9606\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9370\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9528\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9291\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9528\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9685\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9685\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9921\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9685\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0637 - accuracy: 0.9764\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9843\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9764\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9764\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9685\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9764\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9764\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9764\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9764\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9606\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9843\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9606\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9528\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9606\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9843\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9528\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9528\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9764\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9606\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9685\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9764\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9843\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9764\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9685\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9685\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9843\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9685\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9606\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9685\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9843\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9606\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a4ba1d460>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, score_keras = model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy85ZmfpAC3S",
        "outputId": "a09ba01a-b6e4-4974-857c-3faa70498348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 141ms/step - loss: 0.1243 - accuracy: 0.9565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the comparison graph for manual accuracy score and keras accuracy score.\n",
        "labels = ['Manual Algorithm','Manual algo After Hyperparameter tuning', 'keras Algorithm']\n",
        "scores = [score_manual, final_score, score_keras]\n",
        "plt.bar(labels, scores, width = 0.2)\n",
        "plt.ylim([0, 1])\n",
        "plt.title('Accuracy Scores Comparison')\n",
        "plt.xlabel('Algorithm')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "KLdVroy-yX3u",
        "outputId": "0a7b978e-b209-4d97-c710-bc4cd7458a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}